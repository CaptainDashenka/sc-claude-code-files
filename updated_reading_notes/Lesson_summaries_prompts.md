# Prompts & Summaries of Lessons

Here's a summary of Claude Code features and the prompts used in each Lesson.

## Table of Content

- [Summary of Claude Code Features](#summary-of-claude-code-features)
- [Prompts of Lesson 2: Setup & Codebase Understanding](#prompts-of-lesson-2-setup--codebase-understanding)
- [Prompts of Lesson 3: Adding Features](#prompts-of-lesson-3-adding-features)
- [Prompts of Lesson 4: Testing, Error Debugging and Code Refactoring](#prompts-of-lesson-4-testing-error-debugging-and-code-refactoring)
- [Prompts of Lesson 5: Adding Multiple Features Simultaneously - Using Git Worktrees](#prompts-of-lesson-5-adding-multiple-features-simultaneously---using-git-worktrees)
- [Prompts of Lesson 6: References to GitHub Integration & Hooks](#prompts-of-lesson-6-references-to-github-integration--hooks)
- [Prompts of Lesson 7: Refactoring a Jupyter Notebook & Creating a Dashboard](#prompts-of-lesson-7-refactoring-a-jupyter-notebook--creating-a-dashboard)
- [Prompts of Lesson 8: Creating Web App based on a Figma Mockup](#prompts-of-lesson-8-creating-web-app-based-on-a-figma-mockup)
- [Additional Resources](#additional-resources)



## Summary of Claude Code Features

### Managing Project Memory
- `/init`: Claude Code scans your codebase and creates CLAUDE.md file inside your project directory.
    -  CLAUDE.md guides Claude through your codebase, pointing out important commands, architecture and coding style. It's automatically included in the context each time you launch Claude Code.
    - Here's an [example](https://github.com/https-deeplearning-ai/ragchatbot-codebase/blob/main/CLAUDE.md) of a CLAUDE.md file generated by `init` for the RAG chatbot example.

- `#`: Use `#` to quickly add a memory. Useful when you see Claude Code repeats an error.
    - **Example 1**: since the project is a `uv` project, we added these to CLAUDE.md file using `#`:
        - `#`use uv to run python files or add any dependencies
    - **Example 2**: you can inform Claude Code about the database schema, in this case since you have a vector database, you can inform Claude Code about the collections stored in the vector database:
        - `#`The vector database has two collections:
            - `course_catalog`:
                - stores course titles for name resolution
                - metadata for each course: title, instructor, course_link, lesson_count, lessons_json (list of lessons: lesson_number, lesson_title, lesson_link)
            - `course_content`:
                - stores text chunks for semantic search
                - metadata for each chunk: course_title, lesson_number, chunk_index

### Summary of Claude Code Commands

| Command | Description |
|---------|-------------|
| `/clear` | clears current conversation history |
| `/compact` | summarizes current conversation history |
| `ESC` | interrupt Claude to redirect or correct it |
| `ESC ESC` | rewind the conversation to an earlier point in time |
| `@` | Mention files with `@` to include its content in your request|
| `/mcp` | Manage MCP connection & check available MCP servers with their provided tools ([MCP with Claude Code](https://docs.anthropic.com/en/docs/claude-code/mcp))|

You can use regular bash command within Claude Code, but you need to start the command with `!` (for example: `!pwd`). You can type `exit` to quit Claude Code. 

| Shortcuts | Description |
|---------|-------------|
| `shift`+`tab` | switch between planning and auto-accept mode |
| take a screenshot|  `cmd`+ `shift`+ `ctrl` + `4` (Mac) or `Win` + `Shift` + `S` (Windows) |
|paste a screenshot |  `Ctrl` + `V` (might not work on Windows)|

## Summary of Claude Features

- **Extended Thinking Mode**

   For complex tasks (e.g., complex architectural changes, debugging complicated issues), you can use the word "think" to trigger [extended thinking mode](https://docs.anthropic.com/en/docs/claude-code/common-workflows#use-extended-thinking). There are several levels of thinking: "think" < "think hard" < "think harder" < "ultrathink." Each level allocates more thinking budget for Claude.

- **Use of subagents**

   You've learned that one of the out-of-the-box tools for Claude Code is **Task**, which Claude Code can use to launch subagents for complex multi-step tasks. You can explicitly ask Claude Code to use subagents to brainstorm ideas or to investigate multiple aspects of a question or a problem you want to solve. These built-in agents are of general purpose. 

   You can also create your customized specialized subagents. Each subagent has its own context window, and you can define a custom system prompt and specific tools for each subagent. This part is not covered in this course, but you can check the details in the documentation [here](https://docs.anthropic.com/en/docs/claude-code/sub-agents).  

- **Custom Slash Commands**

    - Inside the `.claude` folder of your project directory, create a folder `commands`
    - Inside the `commands` folder, create a markdown file: `implement-feature.md`
    - Copy the following to the markdown file: 
    ```
    You will be implementing a new feature in this codebase
    
    $ARGUMENTS
    
    IMPORTANT: Only do this for front-end features.
    Once this feature is built, make sure to write the changes you made to file called frontend-changes.md
    Do not ask for permissions to modify this file, assume you can always do it.
    ```   
    - Launch again Claude Code, you can now use the command as any other built-in command with Claude Code.


## Prompts of Lesson 2: Setup & Codebase Understanding

### How to Run the RAG Chatbot Application?
- Fork this [repo](https://github.com/https-deeplearning-ai/starting-ragchatbot-codebase.git)
- Clone the forked repo to your local machine
- Follow the instructions in the [README.md file](https://github.com/https-deeplearning-ai/starting-ragchatbot-codebase/blob/main/README.md):
    - If you're using Windows, use Git Bash to run all the commands of the readme file (requires [Git for Windows](https://git-scm.com/downloads/win)). In VS Code, make sure to choose `Git Bash` when you open the terminal.
    - The RAG chatbot application is powered by Claude Sonnet 4 for which you need to specify an Anthropic API key ([Anthropic Console](https://console.anthropic.com/login?returnTo=%2F%3F)). You may choose to enter a fake key and run the application to see how it looks like, but the answers to the queries will fail.  
- You can keep the application running in the background, while going through the lessons. 

### Codebase Exploration

Here are some suggested questions to Claude Code:

<details>
<summary>Give me an overview of this codebase</summary>

<div style="margin-left: 20px;">

**Sample Answer from Claude Code**

Course Materials RAG System Overview

This is a Retrieval-Augmented Generation (RAG) system designed for querying course materials using semantic search and AI-powered responses.

Architecture

Backend (Python/FastAPI):
  - app.py - FastAPI server with CORS/proxy support, serves frontend and API endpoints
  - rag_system.py - Main orchestrator coordinating all components
  - vector_store.py - ChromaDB integration for semantic search
  - ai_generator.py - Anthropic Claude integration for response generation
  - document_processor.py - Text processing and chunking
  - search_tools.py - Tool-based search functionality
  - session_manager.py - Conversation history management
  - models.py - Pydantic models (Course, Lesson, CourseChunk)

Frontend (HTML/CSS/JavaScript):
  - Modern web interface with chat functionality
  - Course statistics sidebar
  - Suggested questions
  - Markdown response rendering

Data Storage:
  - ChromaDB vector database (/chroma_db/)
  - Course documents in /docs/ (txt, pdf, docx support)

Key Features

  - Semantic search across course materials using sentence transformers
  - AI-powered responses with Claude Sonnet 4
  - Session-based conversation history
  - Tool-based search architecture
  - Course analytics and statistics
  - Automatic document processing and chunking
  - Web interface with real-time chat

Dependencies

Python 3.13+, ChromaDB, Anthropic API, FastAPI, sentence-transformers, uvicorn

The system loads course documents on startup and provides both API endpoints (/api/query, /api/courses) and a web interface at http://localhost:8000.

</div>
</details>

<details>
<summary>What are the key data models?</summary>

<div style="margin-left: 20px;">

**Sample Answer from Claude Code**

The key data models are defined using Pydantic:

  1. Course (models.py:10-15)
  - title: Course name (used as unique identifier)
  - course_link: Optional URL to course
  - instructor: Optional instructor name
  - lessons: List of Lesson objects

  2. Lesson (models.py:4-8)
  - lesson_number: Sequential number (0, 1, 2...)
  - title: Lesson title
  - lesson_link: Optional URL to specific lesson

  3. CourseChunk (models.py:17-22)
  - content: Text content of the chunk
  - course_title: Parent course identifier
  - lesson_number: Optional lesson association
  - chunk_index: Position within document

  4. SearchResults (vector_store.py:8-32)
  - documents: List of retrieved text chunks
  - metadata: Associated metadata for each chunk
  - distances: Similarity scores
  - error: Optional error message

  These models create a hierarchical structure: Course → Lessons → CourseChunks, enabling structured storage and retrieval of
   educational content with proper context preservation.

</div>
</details>

<details>
<summary>Explain how the documents are processed</summary>

<div style="margin-left: 20px;">

**Sample Answer from Claude Code**

The document processing system in this codebase works through several key components:

Document Processing Flow

1. Document Reading & Structure Parsing (document_processor.py:13-21)
  - Reads files with UTF-8 encoding, falls back to error-ignoring mode if needed
  - Expects structured format with course metadata in first 3 lines:
    - Line 1: Course Title
    - Line 2: Course Link
    - Line 3: Course Instructor

2. Text Chunking (document_processor.py:25-91)
  - Splits documents into sentence-based chunks with configurable size and overlap
  - Uses regex to detect sentence boundaries while handling abbreviations
  - Maintains context overlap between chunks for better retrieval

3. Course Structure Extraction (document_processor.py:97-259)
  - Parses lesson markers (e.g., "Lesson 0: Introduction")
  - Extracts lesson titles and optional lesson links
  - Creates structured Course and Lesson objects
  - Generates CourseChunk objects with lesson context

4. Vector Storage (vector_store.py:34-267)
  - Uses ChromaDB with sentence transformer embeddings
  - Maintains two collections:
    - course_catalog: Course metadata for semantic search
    - course_content: Actual chunked content for retrieval
  - Supports filtered search by course name and lesson number

Key Features:
  - Preserves lesson structure and adds contextual information to chunks
  - Handles edge cases like files without lesson markers
  - Enables semantic search across courses and within specific lessons
  - Maintains metadata for linking back to original content

The system transforms raw course transcripts into searchable, contextually-aware chunks stored in a vector database for RAG applications.

</div>
</details>

<details>
<summary>What is the format of the document expected by the document_processor?</summary>

<div style="margin-left: 20px;">

**Sample Answer from Claude Code**

Based on the document_processor.py code, the expected document format is:

  Required Structure:
  Course Title: [title]
  Course Link: [url]
  Course Instructor: [instructor]

  Lesson 0: [lesson title]
  Lesson Link: [optional lesson url]
  [lesson content...]

  Lesson 1: [lesson title]
  Lesson Link: [optional lesson url]
  [lesson content...]

  Key Format Rules:
  - Lines 1-3: Course metadata (title, link, instructor)
  - Lesson markers: Must start with "Lesson [number]: [title]" (case-insensitive)
  - Lesson links: Optional "Lesson Link: [url]" immediately after lesson marker
  - Content: Everything else becomes lesson content until next lesson marker

  Example:
  Course Title: Introduction to Python
  Course Link: https://example.com/python-course
  Course Instructor: John Doe

  Lesson 0: Getting Started
  Lesson Link: https://example.com/lesson0
  Welcome to Python programming. In this lesson we'll cover...

  Lesson 1: Variables and Data Types
  Basic data types in Python include strings, integers...

  Fallback Behavior:
  - If no lesson markers found, treats entire content after line 3 as one document
  - Missing metadata lines use defaults (filename for title, "Unknown" for instructor)
  - Empty lines and whitespace are handled gracefully

  The processor extracts this structure into Course/Lesson objects and creates contextual chunks for vector storage.


</div>
</details>

<details>
<summary>How are the course chunks loaded to the database?</summary>

<div style="margin-left: 20px;">

**Sample Answer from Claude Code**

Course chunks are loaded to the database through this process:

  1. Document Processing (rag_system.py:39)
  course, course_chunks = self.document_processor.process_course_document(file_path)
  - DocumentProcessor reads file and creates CourseChunk objects with content, metadata, and lesson context

  2. Vector Store Addition (rag_system.py:45, vector_store.py:162-180)
  self.vector_store.add_course_content(course_chunks)
  - Extracts content from each chunk
  - Creates metadata with course title, lesson number, and chunk index
  - Generates unique IDs: {course_title}_{chunk_index}
  - Adds to ChromaDB course_content collection with embeddings

  3. Loading Triggers:

  Startup Loading (app.py:88-98)
  - Automatically loads all documents from ../docs folder on server startup
  - Calls rag_system.add_course_folder()

  Batch Folder Processing (rag_system.py:52-94)
  - Processes all .txt, .pdf, .docx files in a folder
  - Checks for existing courses to avoid duplicates
  - Can optionally clear existing data first

  Key Steps in ChromaDB Storage:
  1. Documents → chunk content strings
  2. Metadata → course/lesson/chunk info
  3. IDs → unique identifiers per chunk
  4. Embeddings → generated automatically by sentence transformer

  The system ensures no duplicate courses and maintains referential integrity between course metadata and co

</div>
</details>

<details>
<summary>Trace the process of handling user's query from frontend to backend</summary>

<div style="margin-left: 20px;">

**Sample Answer from Claude Code**

Frontend → Backend Flow

  1. Frontend User Interaction (script.js:45-96)
  - User types query and clicks send or presses Enter
  - sendMessage() disables input, adds user message to chat
  - Makes POST request to /api/query with query and session_id

  2. FastAPI Endpoint (app.py:56-74)
  - Receives POST to /api/query with QueryRequest model
  - Creates new session if none provided: rag_system.session_manager.create_session()
  - Calls rag_system.query(request.query, session_id)

  3. RAG System Processing (rag_system.py:102-140)
  - Formats query into prompt: "Answer this question about course materials: {query}"
  - Retrieves conversation history from session manager
  - Calls AI generator with tools and conversation context
  - Gets sources from tool manager after AI completes
  - Updates conversation history with Q&A pair

  4. AI Generation (ai_generator.py:43-80)
  - Creates Claude API call with system prompt and conversation history
  - Includes search tools if available
  - Sends query to Anthropic Claude API
  - Handles tool calls (search) if AI decides to use them

  5. Tool Execution (when AI calls search)
  - AI can call search tool with specific course/lesson filters
  - Tool manager executes vector store search
  - Returns relevant course chunks to AI
  - AI synthesizes results into final response

  6. Response Path Back
  - AI generator returns response string
  - RAG system returns (response, sources) tuple
  - FastAPI formats as QueryResponse JSON
  - Frontend receives JSON, updates session_id if new
  - Displays response with optional sources in chat

  Key Features:
  - Session management maintains conversation context
  - Tool-based architecture allows AI to search when needed
  - Vector store enables semantic search across course content
  - Error handling at each layer with graceful fallbacks

</div>
</details>

<details>
<summary>Draw a diagram that illustrates this flow</summary>

<div style="margin-left: 20px;">

**Sample Answer from Claude Code**

RAG SYSTEM QUERY FLOW DIAGRAM
================================

```
┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐
│   FRONTEND      │    │    FASTAPI       │    │   RAG SYSTEM    │
│   (script.js)   │    │    (app.py)      │    │ (rag_system.py) │
└─────────────────┘    └──────────────────┘    └─────────────────┘
         │                       │                       │
         │ 1. POST /api/query    │                       │
         │ {query, session_id}   │                       │
         ├──────────────────────▶│                       │
         │                       │ 2. rag_system.query() │
         │                       ├──────────────────────▶│
         │                       │                       │
         │                       │                       ▼
┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐
│ SESSION MANAGER │    │   AI GENERATOR   │    │   TOOL MANAGER  │
│(session_mgr.py) │    │ (ai_generator.py)│    │(search_tools.py)│
└─────────────────┘    └──────────────────┘    └─────────────────┘
         ▲                       ▲                       │
         │ 3. get_history()      │ 4. generate_response() │
         │                       │    + tools             │
         └───────────────────────┼───────────────────────┘
                                 │
                                 ▼
┌─────────────────────────────────────────────────────────────────┐
│                    CLAUDE SONNET 4                             │
│  System: "You are an AI assistant with course search tool..."   │
│  Tools: [CourseSearchTool]                                      │
│  Query: "Answer this question about course materials: ..."     │
└─────────────────────────────────────────────────────────────────┘
                                 │
                                 │ 5. Tool Decision
                                 ▼
┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐
│ COURSE SEARCH   │    │   VECTOR STORE   │    │    CHROMADB     │
│     TOOL        │    │ (vector_store.py)│    │                 │
│(search_tools.py)│    │                  │    │                 │
└─────────────────┘    └──────────────────┘    └─────────────────┘
         │                       │                       │
         │ 6. execute(query,     │                       │
         │    course_name,       │                       │
         │    lesson_number)     │                       │
         ├──────────────────────▶│ 7. search()          │
         │                       ├──────────────────────▶│
         │                       │                       │
         │                       │                       │
         │                       │ ┌─────────────────────┤
         │                       │ │ course_catalog      │
         │                       │ │ - Course resolution │
         │                       │ │                     │
         │                       │ │ course_content      │
         │                       │ │ - Semantic search   │
         │                       │ └─────────────────────┤
         │                       │                       │
         │                       │ 8. SearchResults      │
         │ 9. Formatted results  │◀──────────────────────┤
         │◀──────────────────────┤                       │
         │                       │                       │

         │ 10. Tool results back to Claude
         ▼
┌─────────────────────────────────────────────────────────────────┐
│                    CLAUDE SONNET 4                             │
│  Synthesizes tool results into final answer                    │
└─────────────────────────────────────────────────────────────────┘
                                 │
                                 │ 11. Final response
                                 ▼
┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐
│   RAG SYSTEM    │    │    FASTAPI       │    │   FRONTEND      │
│                 │    │                  │    │                 │
└─────────────────┘    └──────────────────┘    └─────────────────┘
         │                       │                       │
         │ 12. (response,        │                       │
         │     sources)          │                       │
         ├──────────────────────▶│ 13. QueryResponse     │
         │                       │ {answer, sources,     │
         │                       │  session_id}          │
         │                       ├──────────────────────▶│
         │                       │                       │
         │                       │                       │ 14. Update UI
         │                       │                       │ - Add message
         │                       │                       │ - Show sources
         │                       │                       │ - Store session

FLOW SUMMARY:
1. User query → FastAPI endpoint
2. RAG system gets conversation history  
3. AI Generator calls Claude with tools
4. Claude decides to use CourseSearchTool
5. Tool searches ChromaDB collections
6. Results formatted and returned to Claude
7. Claude synthesizes final answer
8. Response flows back through layers
9. Frontend displays answer with sources
```

KEY ARCHITECTURE POINTS:
========================

**Dual ChromaDB Collections**: 
- `course_catalog` for name resolution
- `course_content` for semantic search

**Tool-Based Search**: 
- Claude decides when to search vs. use general knowledge

**Session Continuity**: 
- Conversation history maintained across queries

**Error Handling**: 
- Each layer handles failures gracefully

**Source Tracking**: 
- Search results include course/lesson context for UI

DETAILED COMPONENT BREAKDOWN:
============================

Frontend (script.js):
- Handles user input and displays responses
- Manages session state and loading animations
- Renders sources and markdown content

FastAPI (app.py):
- Provides REST API endpoints
- Handles request/response serialization
- Manages CORS and static file serving

RAG System (rag_system.py):
- Main orchestrator coordinating all components
- Manages session creation and conversation history
- Routes queries through AI generator with tools

AI Generator (ai_generator.py):
- Interfaces with Claude Sonnet 4 API
- Handles tool calling workflow
- Manages conversation context and system prompts

Search Tools (search_tools.py):
- Implements CourseSearchTool for semantic search
- Formats search results with course/lesson context
- Tracks sources for UI display

Vector Store (vector_store.py):
- ChromaDB wrapper with dual collection strategy
- Provides course name resolution and content search
- Uses sentence-transformers for embeddings

Session Manager (session_manager.py):
- Maintains conversation history per session
- Provides context for follow-up questions

</div>
</details>


<details>
<summary>Explain how the text is transformed into chunks? What is the size of each chunk?</summary>

<div style="margin-left: 20px;">

**Sample Answer from Claude Code**
Looking at the chunking process in document_processor.py:25-91:

  Text Chunking Process

  1. Text Preprocessing (lines 28-29)
  - Normalizes whitespace: re.sub(r'\s+', ' ', text.strip())
  - Removes extra spaces and line breaks

  2. Sentence Splitting (lines 31-38)
  - Uses regex to split on sentence boundaries: (?<!\w\.\w.)(?<![A-Z][a-z]\.)(?<=\.|\!|\?)\s+(?=[A-Z])
  - Handles abbreviations (avoids splitting on "Mr.", "Dr.", etc.)
  - Splits on periods, exclamation marks, question marks followed by capital letters

  3. Chunk Building Algorithm (lines 40-91)
  - Sentence-based chunking: Builds chunks by adding complete sentences
  - Size limit: Stops adding sentences when current_size + sentence_length > chunk_size
  - Overlap calculation: Uses configurable overlap between chunks for context preservation

  Chunk Size Configuration

  The chunk size comes from config.py settings:

⏺ Read(backend/config.py)
  ⎿  Read 30 lines (ctrl+r to expand)

⏺ Chunk Configuration

  - Chunk Size: 800 characters (config.py:19)
  - Chunk Overlap: 100 characters (config.py:20)

  Chunking Strategy

  Smart Sentence Boundaries:
  - Never splits mid-sentence - always completes sentences
  - If a single sentence exceeds 800 chars, it becomes its own chunk
  - Maintains readability and context

  Overlap Implementation (lines 67-83):
  - Counts backwards from end of current chunk
  - Includes previous sentences up to 100 characters
  - Ensures context continuity between chunks
  - Prevents information loss at chunk boundaries

  Context Enhancement (lines 184-188, 232-234):
  - First chunk of each lesson: "Lesson {N} content: {chunk}"
  - Other chunks: "Course {title} Lesson {N} content: {chunk}"
  - Adds lesson/course context for better retrieval

  Example Process:
  Input: "This is sentence one. This is sentence two. This is sentence three."
  ↓
  Chunks with 800 char limit, 100 char overlap:
  - Chunk 1: "Lesson 1 content: This is sentence one. This is sentence two."
  - Chunk 2: "This is sentence two. This is sentence three." (overlap)

  This approach balances chunk size for embedding efficiency while preserving semantic meaning and context.



</div>
</details>

<details>
<summary>Describe the api endpoints</summary>

<div style="margin-left: 20px;">

**Sample Answer from Claude Code**

Based on app.py, the API has these endpoints:

  API Endpoints

  POST /api/query

  Purpose: Process user queries and return AI-generated responses

  Request Model (app.py:38-41):
  {
    "query": "string",
    "session_id": "string" // optional
  }

  Response Model (app.py:43-47):
  {
    "answer": "string",
    "sources": ["string"],
    "session_id": "string"
  }

  Process (app.py:56-74):
  - Creates new session if none provided
  - Calls RAG system to process query
  - Returns AI response with sources and session ID
  - Handles errors with 500 status code

  GET /api/courses

  Purpose: Get course analytics and statistics

  Response Model (app.py:49-52):
  {
    "total_courses": 0,
    "course_titles": ["string"]
  }

  Process (app.py:76-86):
  - Calls rag_system.get_course_analytics()
  - Returns course count and list of all course titles
  - Used by frontend to display available courses

  Static File Serving

  Mount: "/" → ../frontend/ (app.py:119)
  - Serves frontend HTML, CSS, JS files
  - Uses custom DevStaticFiles class with no-cache headers for development
  - Enables SPA routing with html=True

  Middleware Configuration

  CORS (app.py:24-32):
  - Allows all origins (allow_origins=["*"])
  - Enables credentials and all methods/headers
  - Required for frontend-backend communication

  TrustedHost (app.py:18-22):
  - Allows all hosts (allowed_hosts=["*"])
  - Handles proxy configurations

  Startup Event (app.py:88-98)

  - Automatically loads documents from ../docs folder
  - Processes course files into vector database
  - Logs loading progress and errors

  The API follows REST principles with clear request/response models and proper error handling.
</div>
</details>

<details>
<summary>How can I run the application?</summary>

<div style="margin-left: 20px;">

**Sample Answer from Claude Code**

Based on the codebase, here are the ways to run the application:

  **Quick Start (Recommended)**

  chmod +x run.sh
  ./run.sh

  **Manual Start**

  cd backend
  uv run uvicorn app:app --reload --port 8000

  **Prerequisites**

  1. Make sure you have uv installed
  2. Install dependencies: uv sync
  3. Create a .env file with your Anthropic API key:
  ANTHROPIC_API_KEY=your_anthropic_api_key_here

  The application will be available at:
  - Web Interface: http://localhost:8000
  - API Documentation: http://localhost:8000/docs

</div>
</details>



## Prompts of Lesson 3: Adding Features

### Prompt Used for each feature

#### Feature 1 - Embed links in the source citations

For each response, the chatbot returns the lesson that it used to answer the query. The vector store has two collections: one for the lesson chunks and another for the course metadata, which includes a link to each lesson. So assume you want to embed the links of the returned sources in the UI and you want Claude Code to help with that:

Here's a sample prompt (used with plan mode):
 ```
The chat interface displays query responses with source citations. I need to modify it so each source becomes a clickable link that opens the corresponding lesson video in a new tab:
- When courses are processed into chunks in @backend/document_processor.py, the link of each lesson is stored in the course_catalog collection
- Modify _format_results in @backend/search_tools.py so that the lesson links are  also returned
- The links should be embedded invisibly (no visible URL text)
```

Follow-up request:
```
[Ctrl + V to paste the screenshot] these links are hard to read. Make them more visually appealing.
```

#### Feature 2 - Add '+ New Chat' Feature

Here's the prompt:
```
Add a '+ NEW CHAT' button to the left sidebar above the courses section. When clicked, it should:
- Clear the current conversation in the chat window
- Start a new session without page reload
- Handle proper cleanup on both @frontend and @backend
- Match the styling of existing sections (Courses, Try asking) - same font size, color, and uppercase formatting
```

Configuration of [Playwright MCP server](https://github.com/microsoft/playwright-mcp):
- exit Claude Code
- in the terminal, type: `claude mcp add playwright npx @playwright/mcp@latest` 
- open Claude Code again and verify you are connected to the MCP server using `/mcp` command

Here's the followup request:
```
Using the playwright MCP server, visit 127.0.0.1:8000 and view the '+ New Chat' button. I want that button to look the same as the other links below for Courses and Try Asking. Make sure this is left aligned and that the border is removed.
```
*Side note*: By default, Claude Code will ask you for your permission to use the "take a screenshot tool" of playwright. You can choose to always allow it when asked by Claude Code or you can manually configure this setting: type `/permissions` command -> Add a new rule (make sure that 'Allow' is highlighted) -> then you specify the full name of the tool. To type the full name of the screenshot tool, in Claude Code terminal, you can type `/mcp` -> choose your MCP server (in this case playwright) -> view tools -> 14. Take a screenshot -> you'll see the full name "mcp__playwright__browser_take_screenshot".



#### Feature 3 - Adding a tool to the chatbot

If you check the [search_tools.py](https://github.com/https-deeplearning-ai/starting-ragchatbot-codebase/blob/main/backend/search_tools.py) in the starting codebase, you will see that there is one tool defined for the RAG chatbot. Assume you now want to define another tool for the RAG chatbot to handle outline-related questions. So instead of relying on the content received to answer outline questions, you want the exact outline to be returned (title of each lesson, course link, course title). The course_metadata collection in the vector database has this info. You can ask Claude Code to implement this tool for you:

Here's the prompt used:

```
In @backend/search_tools.py, add a second tool alongside the existing content-related tool. This new tool should handle course outline queries.
- Functionality:
   - Input: Course title
   - Output: Course title, course link, and complete lesson list
   - For each lesson: lesson number, lesson title
- Data source: Course metadata collection of the vector store
- Update the system prompt in @backend/ai_generator so that the course title, course link, the number and title of each lesson are all returned to address an outline-related queries.
- Make sure that the new tool is registered in the system. 
```



## Prompts of Lesson 4: Testing, Error Debugging and Code Refactoring

### Error Debugging

To create the error, we intentionally set `MAX_RESULTS: int = 0` in backend/config.py. 

Here's the prompt used with Plan mode:

```
The RAG chatbot returns 'query failed' for any content-related questions. I need you to:
1. Write tests to evaluate the outputs of the execute method of the CourseSearchTool in @backend/search_tools.py 
2. Write tests to evaluate if @backend/ai_generator.py correctly calls for the CourseSearchTool 
3. Write tests to evaluate how the RAG system is handling the content-query related questions. 

Save the tests in a tests folder within @backend. Run those tests against the current system to identify which components are failing. Propose fixes based on what the tests reveal is broken.

Think.
```

### Code Refactoring

In backend/ai_generator.py of the starting codebase, the chatbot is designed to use one tool call per query. To handle more complex queries, you can ask Claude 
Code to refactor it so it can handle sequential tool calls. 

Prompt:

```
Refactor @backend/ai_generator.py to support sequential tool calling where Claude can make up to 2 tool calls in separate API rounds.

Current behavior:
- Claude makes 1 tool call → tools are removed from API params → final response
- If Claude wants another tool call after seeing results, it can't (gets empty response)

Desired behavior:
- Each tool call should be a separate API request where Claude can reason about previous results
- Support for complex queries requiring multiple searches for comparisons, multi-part questions, or when information from different courses/lessons is needed

Example flow:
1. User: "Search for a course that discusses the same topic as lesson 4 of course X"
2. Claude: get course outline for course X → gets title of lesson 4
3. Claude: uses the title to search for a course that discusses the same topic → returns course information
4. Claude: provides complete answer

Requirements:
- Maximum 2 sequential rounds per user query
- Terminate when: (a) 2 rounds completed, (b) Claude's response has no tool_use blocks, or (c) tool call fails
- Preserve conversation context between rounds
- Handle tool execution errors gracefully

Notes: 
- Update the system prompt in @backend/ai_generator.py 
- Update the test @backend/tests/test_ai_generator.py
- Write tests that verify the external behavior (API calls made, tools executed, results returned) rather than internal state details. 

Use two parallel subagents to brainstorm possible plans. Do not implement any code.

```


## Prompts of Lesson 5: Adding Multiple Features Simultaneously - Using Git Worktrees

### What are git Worktrees?

Git worktrees allow you to check out multiple branches from the same repository into separate directories. Each worktree represents a copy of your working directory with isolated files but shares the same Git history.

### Workflow

- Make sure first that you've added and committed any previous changes to the codebase.
- Create the folder .trees: `mkdir .trees`.
- For each feature you want to implement, create a worktree:
   - `git worktree add .trees/ui_feature`
   - `git worktree add .trees/testing_feature`
   - `git worktree add .trees/quality_feature`
- From each worktree, open an integrated terminal, launch Claude code in each terminal, and ask it to implement each feature.
- For each worktree, add and commit the changes in each worktree.
- Close claude terminals.
- In the main terminal: ask Claude Code to git merge the worktrees and resolve any merge conflicts (```use the git merge command to merge in all the worktrees of the .trees folder into main and fix any conflicts if there are any```)


### Prompt Used for each feature

#### UI Feature

```
Add a toggle button that allows users to switch between dark and light themes.

1. Toggle Button Design
    - Create a toggle button that fits the existing design aesthetic
    - Position it in the top-right
    - Use an icon-based design (sun/moon icons or similar)
    - Smooth transition animation when toggling
    - Button should be accessible and keyboard-navigable

2. Light Theme CSS Variables
    Add a light theme variant with appropriate colors:
    - Light background colors
    - Dark text for good contrast
    - Adjusted primary and secondary colors
    - Proper border and surface colors
    - Maintain good accessibility standards

3. JavaScript Functionality
    - Toggle between themes on button click
    - Smooth transitions between themes

4. Implementation Details
    - Use CSS custom properties (CSS variables) for theme switching
    - Add a `data-theme` attribute to the body or html element
    - Ensure all existing elements work well in both themes
    - Maintain the current visual hierarchy and design language

```

#### Testing Feature

```
Enhance the existing testing framework for the RAG system in @backend/tests. The current tests cover unit components but are missing essential API testing infrastructure:

- API endpoint tests - Test the FastAPI endpoints (/api/query, /api/courses, /) for proper request/response handling
- pytest configuration - Add pytest.ini_options in pyproject.toml for cleaner test execution
- Test fixtures - Create conftest.py with shared fixtures for mocking and test data setup

The FastAPI app in backend/app.py mounts static files that don't exist in the test environment. Either create a separate test app or define the API endpoints inline in the test file to avoid import issues.
```

#### Quality Feature

```
Add essential code quality tools to the development workflow. Set up black for automatic code formatting. Add proper formatting consistency throughout the codebase and create development scripts for running quality checks.
```


## Prompts of Lesson 6: References to GitHub Integration & Hooks

### GitHub Integration

Claude Code GitHub Actions brings Claude to your GitHub workflow. Once you set it up, you can mention `@claude` in any pull request or issue. It can implement code, create pull request and review code. The easiest way to set it up this is through Claude Code in the terminal by running `/install-github-app`.

You can check the documentation [here](https://docs.anthropic.com/en/docs/claude-code/github-actions) for more information on how to use this integration. 

### Hooks

Claude Code hooks are shell commands that you can define and can be executed at various points in Claude Code’s lifecycle (before tool execution, after tool execution, when subagent finishes a task, when claude finishes responding).  

We showed a quick example on hooks in this lesson. If you'd like to learn more about hooks and see more examples, you are encouraged to check out:
- "Hooks" in Anthropic's [Claude Code In action](https://anthropic.skilljar.com/claude-code-in-action/312000).
- Documentation: [Hooks guide](https://docs.anthropic.com/en/docs/claude-code/hooks-guide) and [hooks reference](https://docs.anthropic.com/en/docs/claude-code/hooks).

## Prompts of Lesson 7: Refactoring a Jupyter Notebook & Creating a Dashboard

### Refactoring Prompt

```
The @EDA.ipynb contains exploratory data analysis on e-commerce data in @ecommerce_data, focusing on sales metrics for 2023. Keep the same analysis and graphs, and improve the structure and documentation of the notebook.

Review the existing notebook and identify:
- What business metrics are currently calculated
- What visualizations are created
- What data transformations are performed
- Any code quality issues or inefficiencies
  
**Refactoring Requirements**

1. Notebook Structure & Documentation
    - Add proper documentation and markdown cells with clear header and a brief explanation for the section
    - Organize into logical sections:
        - Introduction & Business Objectives
        - Data Loading & Configuration
        - Data Preparation & Transformation
        - Business Metrics Calculation (revenue, product, geographic, customer experience analysis)
        - Summary of observations
    - Add table of contents at the beginning
    - Include data dictionary explaining key columns and business terms
   
2. Code Quality Improvements
   - Create reusable functions with docstrings
   - Implement consistent naming and formatting
   - Create separate Python files:
 	- business_metrics.py containing business metric calculations only
	- data_loader.py loading, processing and cleaning the data  
        
3. Enhanced Visualizations
    - Improve all plots with:
        - Clear and descriptive titles 
        - Proper axis labels with units
        - Legends where needed
        - Appropriate chart types for the data
        - Include date range in plot titles or captions
        - use consistent color business-oriented color schemes
          
4. Configurable Analysis Framework
The notebook shows the computation of metrics for a specific date range (entire year of 2023 compared to 2022). Refactor the code so that the data is first filtered according to configurable month and year & implement general-purpose metric calculations. 
       

**Deliverables Expected**
- Refactored Jupyter notebook (EDA_Refactored.ipynb) with all improvements
- Business metrics module (business_metrics.py) with documented functions
- Requirements file (requirements.txt) listing all dependencies
- README section explaining how to use the refactored analysis

**Success Criteria**
- Easy-to read code & notebook (do not use icons in the printing statements or markdown cells)
- Configurable analysis that works for any date range
- Reusable code that can be applied to future datasets
- Maintainable structure that other analysts can easily understand and extend
- Maintain all existing analyses while improving the quality, structure, and usability of the notebook.
- Do not assume any business thresholds.

```

### Prompt for Converting to Dashboards (Streamlit)

```
Convert `@EDA_Refactored.ipynb` into a professional Streamlit dashboard with this exact layout:

## Layout Structure
- **Header**: Title + date range filter (applies globally)
    - Title: left
    - Date range filter: right
- **KPI Row**: 4 cards (Total Revenue, Monthly Growth, Average order Value, Total Orders)
    - Trend indicators for Total Revenue, Average Order Value and Total Orders
    - Use red for negative trends and green for positive trend
- **Charts Grid**: 2x2 layout
  - Revenue trend line chart:
      - solid line for the current period
      - dashed line for the previous period
      - Add grid lines for easier reading
      - Y-axis formatting - show values as $300K instead of $300,000
  - Top 10 categories bar chart sorted descending:
      - Use blue gradient (light shade for lower values)
      - Format values as $300K and $2M  
  - Revenue by state: US choropleth map Color-coded by revenue amount
      - Use blue gradient
  - Bar chart showing satisfaction vs delivery time:
	- x-axis: Delivery time buckets (1-3 days, 4-7 days, etc.)
	- y-axis: Average review score
- **Bottom Row**: 2 cards 
   - Average delivery time with trend indicator
   - Review Score:
   	- Large number with stars
   	- Subtitle: "Average Review Score"

## Key Requirements
- Use Plotly for all charts
- Filter update charts correctly
- Professional styling with trend arrows/colors
- Do not use icons
- Use uniform card heights for each row
- Show two decimal places for each trend indicator
- Include requirements.txt and README.md

```

## Prompts of Lesson 8: Creating Web App based on a Figma Mockup

### Figma Design

Here's the [Figma design mockup](https://github.com/https-deeplearning-ai/sc-claude-code-files/blob/main/additional_files/key-indicators.fig) that you can open with [Figma desktop app](https://www.figma.com/downloads/). 

In the terminal, initialize your `next.js` application using this command:
`npx create-next-app@latest .`

### Figma Official MCP Server (Dev Mode MCP Server)

Note: The official MCP server provided by Figma requires [Dev or Full seat](https://help.figma.com/hc/en-us/articles/27468498501527-Updates-to-Figma-s-pricing-seats-and-billing-experience#h_01JCPBM8X2MBEXTABDM92HWZG4) on the [Professional, Organization, or Enterprise plans](https://help.figma.com/hc/en-us/articles/360040328273-Figma-plans-and-features). You can check [this guide](https://help.figma.com/hc/en-us/articles/32132100833559-Guide-to-the-Dev-Mode-MCP-Server) for more details. There's another Figma MCP server provided by framelinks that you can use for free. Please check the last section of this note for more details. 

### Enable MCP Server

- Open the [Figma design](https://github.com/https-deeplearning-ai/sc-claude-code-files/blob/main/additional_files/key-indicators.fig) in Figma desktop app. 
- In the upper-left corner, open the Figma menu.
- Under Preferences, select Enable Dev Mode MCP Server (as shown [here](https://help.figma.com/hc/article_attachments/33880427925271)).
 
You should see a confirmation message at the bottom of the screen letting you know the server is enabled and running locally at `http://127.0.0.1:3845/mcp` (remote server running locally using http transport). 

#### Configure the MCP Server for Claude Code

- In the terminal, type: `claude mcp add --transport http figma-dev-mode-mcp-server http://127.0.0.1:3845/mcp`.

- Also add MCP playwright server: `claude mcp add playwright npx @playwright/mcp@latest`.

- Launch Claude Code and verify that you're connected to both MCP servers (using `/mcp`).


### Prompt 

- To copy the Figma design, in Figma desktop select the design and then click on `Ctrl`+ `L` or `cmd` + `L`.

- Here's the prompt:

  ```
  Using the following figma mockup (paste the link) use the figma dev MCP server to analyze the mockup and build the underlying code in this next.js application. Use the recharts library for creating charts to make this a web application. Check how this application looks using the playwright MCP server and verify it looks as close to the mock as possible.
  ```   

- Follow-up request:

  ``` 
  populate these charts with real-world data from FRED
  ```

  If you'd like to connect the dashboard to real data, then you need at get an API key from FRED [here](https://fred.stlouisfed.org/docs/api/api_key.html).



### Alternative to Figma Official MCP server - Framelink Figma MCP server 

Here's a [guide](https://www.framelink.ai/docs/quickstart?utm_source=github&utm_medium=referral&utm_campaign=readme) on how to configure the Framelink Figma MCP server (as well as some [best practices](https://www.framelink.ai/docs/best-practices) for using it)

You can configure it for Claude Code using: 

`claude mcp add "Framelink Figma MCP" -- npx -y figma-developer-mcp --figma-api-key=YOUR-KEY --stdio`

Or this command:

`claude mcp add-json "Framelink-Figma-MCP" '{"command": "npx", "args": ["-y", "figma-developer-mcp", "--figma-api-key=YOUR-KEY","--stdio"]}'`


## Additional Resources

To learn more about these features as well as other features, you can check: 
- [Claude Code Documentation](https://docs.anthropic.com/en/docs/claude-code/overview)
- [Claude Code Common Workflows](https://docs.anthropic.com/en/docs/claude-code/common-workflows)
- [Claude Code Best Practices](https://www.anthropic.com/engineering/claude-code-best-practices)
- [Claude Code Use Cases](https://www.anthropic.com/news/how-anthropic-teams-use-claude-code)

There's also a great course on Anthropic Academy that you can check out to see more examples with Claude Code:
- [Claude Code in Action](https://anthropic.skilljar.com/claude-code-in-action)
